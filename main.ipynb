{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema PSO para Otimiza√ß√£o de Hiperpar√¢metros - Classifica√ß√£o de Parkinson\n",
    "\n",
    "Este notebook implementa um sistema modular para otimiza√ß√£o de hiperpar√¢metros de uma rede neural feedforward usando Particle Swarm Optimization (PSO) para classifica√ß√£o bin√°ria de Parkinson.\n",
    "\n",
    "## Caracter√≠sticas do Sistema:\n",
    "- 32 experimentos independentes\n",
    "- Armazenamento completo em SQLite\n",
    "- Monitoramento de recursos (CPU, mem√≥ria, disco)\n",
    "- Barras de progresso com tqdm.notebook\n",
    "- Avalia√ß√£o final com valida√ß√£o cruzada estratificada\n",
    "\n",
    "## Estrutura do Projeto:\n",
    "- `config.py`: Configura√ß√µes centralizadas\n",
    "- `data_utils.py`: Carregamento e prepara√ß√£o dos dados\n",
    "- `model_utils.py`: Constru√ß√£o e treino da rede neural\n",
    "- `database_utils.py`: Cria√ß√£o e manipula√ß√£o do SQLite\n",
    "- `pso_optimizer.py`: Execu√ß√£o do PSO com registro completo\n",
    "- `evaluate_final_model.py`: Avalia√ß√£o do melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importa√ß√µes e Configura√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy pandas tensorflow scikit-learn matplotlib seaborn tqdm psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Configurar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Importar m√≥dulos do projeto\n",
    "import config\n",
    "import data_utils\n",
    "import model_utils\n",
    "import database_utils\n",
    "import pso_optimizer\n",
    "import evaluate_final_model\n",
    "\n",
    "print(\"‚úÖ Importa√ß√µes realizadas com sucesso!\")\n",
    "print(f\"üìä Configura√ß√£o PSO: {config.PSO_CONFIG['n_particles']} part√≠culas, {config.PSO_CONFIG['iters']} itera√ß√µes, {config.PSO_CONFIG['experimentos']} experimentos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explora√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e explorar dados\n",
    "print(\"üìä Carregando dataset de Parkinson...\")\n",
    "df = data_utils.load_parkinson_data()\n",
    "\n",
    "# Validar dados\n",
    "data_utils.validate_data(df)\n",
    "\n",
    "# Informa√ß√µes do dataset\n",
    "info = data_utils.get_data_info(df)\n",
    "print(f\"\\nüìà Informa√ß√µes do Dataset:\")\n",
    "print(f\"  ‚Ä¢ Amostras: {info['n_samples']}\")\n",
    "print(f\"  ‚Ä¢ Features: {info['n_features']}\")\n",
    "print(f\"  ‚Ä¢ Distribui√ß√£o de classes: {info['target_distribution']}\")\n",
    "print(f\"  ‚Ä¢ Valores ausentes: {info['missing_values']}\")\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o das classes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "plt.subplot(1, 2, 1)\n",
    "class_counts = df['status'].value_counts()\n",
    "plt.bar(['Saud√°vel (0)', 'Parkinson (1)'], class_counts.values, color=['lightblue', 'lightcoral'])\n",
    "plt.title('Distribui√ß√£o das Classes')\n",
    "plt.ylabel('N√∫mero de Amostras')\n",
    "\n",
    "# Gr√°fico de pizza\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(class_counts.values, labels=['Saud√°vel', 'Parkinson'], autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])\n",
    "plt.title('Propor√ß√£o das Classes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dataset balanceado: {'Sim' if abs(class_counts[0] - class_counts[1]) / len(df) < 0.1 else 'N√£o'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para valida√ß√£o cruzada\n",
    "print(\"üîÑ Preparando dados para valida√ß√£o cruzada...\")\n",
    "X_data, y_data, scaler = data_utils.prepare_data_for_cv(df)\n",
    "\n",
    "print(f\"‚úÖ Dados preparados:\")\n",
    "print(f\"  ‚Ä¢ Shape X: {X_data.shape}\")\n",
    "print(f\"  ‚Ä¢ Shape y: {y_data.shape}\")\n",
    "print(f\"  ‚Ä¢ Tipo de normaliza√ß√£o: MinMaxScaler\")\n",
    "print(f\"  ‚Ä¢ Range dos dados: [{X_data.min():.3f}, {X_data.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Teste R√°pido da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar cria√ß√£o e treino de uma rede neural simples\n",
    "print(\"üß™ Testando cria√ß√£o e treino da rede neural...\")\n",
    "\n",
    "# Par√¢metros de teste\n",
    "test_params = {\n",
    "    'n_layers': 2,\n",
    "    'neurons': [64, 32],\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "\n",
    "# Dividir dados para teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_test, X_val_test, y_train_test, y_val_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    ")\n",
    "\n",
    "# Criar e treinar modelo\n",
    "test_model = model_utils.create_neural_network(X_data.shape[1], test_params)\n",
    "print(f\"‚úÖ Modelo criado com arquitetura: {test_params['neurons']}\")\n",
    "\n",
    "# Treinar por algumas √©pocas\n",
    "history = model_utils.train_neural_network(\n",
    "    test_model, X_train_test, y_train_test, \n",
    "    X_val_test, y_val_test, epochs=10, verbose=1\n",
    ")\n",
    "\n",
    "# Avaliar modelo\n",
    "metrics = model_utils.evaluate_model(test_model, X_val_test, y_val_test)\n",
    "print(f\"\\nüìä M√©tricas do teste:\")\n",
    "print(f\"  ‚Ä¢ F1-Score: {metrics['f1_score']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ AUC: {metrics['auc']:.4f}\")\n",
    "\n",
    "# Limpar mem√≥ria\n",
    "del test_model\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"‚úÖ Teste da rede neural conclu√≠do com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execu√ß√£o da Otimiza√ß√£o PSO\n",
    "\n",
    "‚ö†Ô∏è **ATEN√á√ÉO**: Esta etapa pode demorar v√°rias horas para ser conclu√≠da (32 experimentos √ó 30 itera√ß√µes √ó 20 part√≠culas = 19.200 treinamentos de rede neural).\n",
    "\n",
    "Para teste r√°pido, voc√™ pode reduzir os valores em `config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar configura√ß√µes antes de executar\n",
    "print(\"‚öôÔ∏è Configura√ß√µes atuais do PSO:\")\n",
    "print(f\"  ‚Ä¢ Experimentos: {config.PSO_CONFIG['experimentos']}\")\n",
    "print(f\"  ‚Ä¢ Part√≠culas por experimento: {config.PSO_CONFIG['n_particles']}\")\n",
    "print(f\"  ‚Ä¢ Itera√ß√µes por experimento: {config.PSO_CONFIG['iters']}\")\n",
    "print(f\"  ‚Ä¢ Total de treinamentos: {config.PSO_CONFIG['experimentos'] * config.PSO_CONFIG['n_particles'] * config.PSO_CONFIG['iters']:,}\")\n",
    "\n",
    "# Estimar tempo\n",
    "estimated_time_hours = (config.PSO_CONFIG['experimentos'] * config.PSO_CONFIG['n_particles'] * config.PSO_CONFIG['iters'] * 2) / 3600\n",
    "print(f\"  ‚Ä¢ Tempo estimado: ~{estimated_time_hours:.1f} horas\")\n",
    "\n",
    "print(\"\\nüí° Para teste r√°pido, edite config.py e reduza os valores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar otimiza√ß√£o PSO\n",
    "print(\"üöÄ Iniciando otimiza√ß√£o PSO...\")\n",
    "print(\"üìä Progresso ser√° mostrado com barras de progresso interativas.\")\n",
    "print(\"üíæ Todos os dados ser√£o salvos automaticamente no banco SQLite.\")\n",
    "\n",
    "# Executar otimiza√ß√£o\n",
    "pso_results = pso_optimizer.run_pso_optimization()\n",
    "\n",
    "print(\"\\nüéâ Otimiza√ß√£o PSO conclu√≠da com sucesso!\")\n",
    "print(f\"üèÜ Melhor F1-Score encontrado: {pso_results['best_experiment']['best_f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√°lise dos Resultados PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter estat√≠sticas dos experimentos\n",
    "stats = database_utils.get_experiment_statistics()\n",
    "\n",
    "print(\"üìä Estat√≠sticas dos Experimentos PSO:\")\n",
    "print(f\"  ‚Ä¢ Total de experimentos: {int(stats.get('total_experiments', 0))}\")\n",
    "print(f\"  ‚Ä¢ Total de part√≠culas avaliadas: {int(stats.get('total_particles', 0)):,}\")\n",
    "print(f\"  ‚Ä¢ F1-Score m√©dio: {stats.get('avg_f1_score', 0):.4f}\")\n",
    "print(f\"  ‚Ä¢ Melhor F1-Score: {stats.get('best_f1_score', 0):.4f}\")\n",
    "print(f\"  ‚Ä¢ Pior F1-Score: {stats.get('worst_f1_score', 0):.4f}\")\n",
    "print(f\"  ‚Ä¢ Desvio padr√£o F1: {stats.get('std_f1_score', 0):.4f}\")\n",
    "print(f\"  ‚Ä¢ Tempo m√©dio por experimento: {stats.get('avg_total_time', 0):.1f}s\")\n",
    "print(f\"  ‚Ä¢ Uso m√©dio de CPU: {stats.get('avg_cpu_usage', 0):.1f}%\")\n",
    "print(f\"  ‚Ä¢ Uso m√°ximo de mem√≥ria: {stats.get('avg_max_memory', 0):.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter melhor part√≠cula\n",
    "best_particle = database_utils.get_best_particle_overall()\n",
    "\n",
    "if best_particle:\n",
    "    print(\"üèÜ Melhor Part√≠cula Encontrada:\")\n",
    "    print(f\"  ‚Ä¢ Experimento: {best_particle['experiment']}\")\n",
    "    print(f\"  ‚Ä¢ Itera√ß√£o: {best_particle['iteration']}\")\n",
    "    print(f\"  ‚Ä¢ Part√≠cula: {best_particle['particle']}\")\n",
    "    print(f\"  ‚Ä¢ F1-Score: {best_particle['f1_score']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ N√∫mero de camadas: {best_particle['num_layers']}\")\n",
    "    \n",
    "    # Decodificar par√¢metros\n",
    "    best_params = model_utils.decode_particle_position(best_particle['position'])\n",
    "    print(f\"  ‚Ä¢ Arquitetura: {best_params['neurons'][:best_params['n_layers']]}\")\n",
    "    print(f\"  ‚Ä¢ Learning Rate: {best_params['learning_rate']:.6f}\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum resultado encontrado no banco de dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar converg√™ncia dos experimentos\n",
    "convergence_data = database_utils.get_convergence_data()\n",
    "\n",
    "if len(convergence_data) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Converg√™ncia por experimento\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for exp in convergence_data['num_experimento'].unique()[:10]:  # Mostrar apenas 10 experimentos\n",
    "        exp_data = convergence_data[convergence_data['num_experimento'] == exp]\n",
    "        plt.plot(exp_data['num_iteracao'], exp_data['best_f1_score'], alpha=0.7, label=f'Exp {exp}')\n",
    "    plt.xlabel('Itera√ß√£o')\n",
    "    plt.ylabel('Melhor F1-Score')\n",
    "    plt.title('Converg√™ncia por Experimento (10 primeiros)')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 2: M√©dia de converg√™ncia\n",
    "    plt.subplot(2, 2, 2)\n",
    "    avg_convergence = convergence_data.groupby('num_iteracao').agg({\n",
    "        'best_f1_score': ['mean', 'std'],\n",
    "        'avg_f1_score': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    iterations = avg_convergence['num_iteracao']\n",
    "    best_mean = avg_convergence[('best_f1_score', 'mean')]\n",
    "    best_std = avg_convergence[('best_f1_score', 'std')]\n",
    "    avg_mean = avg_convergence[('avg_f1_score', 'mean')]\n",
    "    \n",
    "    plt.plot(iterations, best_mean, 'b-', label='Melhor F1 (m√©dia)', linewidth=2)\n",
    "    plt.fill_between(iterations, best_mean - best_std, best_mean + best_std, alpha=0.3, color='blue')\n",
    "    plt.plot(iterations, avg_mean, 'r--', label='F1 m√©dio', linewidth=2)\n",
    "    plt.xlabel('Itera√ß√£o')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('Converg√™ncia M√©dia (todos os experimentos)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 3: Distribui√ß√£o dos melhores F1-scores\n",
    "    plt.subplot(2, 2, 3)\n",
    "    best_scores = convergence_data.groupby('num_experimento')['best_f1_score'].max()\n",
    "    plt.hist(best_scores, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "    plt.axvline(best_scores.mean(), color='red', linestyle='--', label=f'M√©dia: {best_scores.mean():.4f}')\n",
    "    plt.xlabel('Melhor F1-Score por Experimento')\n",
    "    plt.ylabel('Frequ√™ncia')\n",
    "    plt.title('Distribui√ß√£o dos Melhores F1-Scores')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 4: Boxplot dos F1-scores por itera√ß√£o\n",
    "    plt.subplot(2, 2, 4)\n",
    "    iterations_sample = [0, 5, 10, 15, 20, 25, 29]  # Amostra de itera√ß√µes\n",
    "    data_for_box = []\n",
    "    labels_for_box = []\n",
    "    \n",
    "    for it in iterations_sample:\n",
    "        iter_data = convergence_data[convergence_data['num_iteracao'] == it]['best_f1_score']\n",
    "        if len(iter_data) > 0:\n",
    "            data_for_box.append(iter_data)\n",
    "            labels_for_box.append(f'It {it}')\n",
    "    \n",
    "    if data_for_box:\n",
    "        plt.boxplot(data_for_box, labels=labels_for_box)\n",
    "        plt.ylabel('F1-Score')\n",
    "        plt.title('Distribui√ß√£o F1-Score por Itera√ß√£o')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìà An√°lise de converg√™ncia:\")\n",
    "    print(f\"  ‚Ä¢ Melhor F1-Score final: {best_scores.max():.4f}\")\n",
    "    print(f\"  ‚Ä¢ F1-Score m√©dio final: {best_scores.mean():.4f}\")\n",
    "    print(f\"  ‚Ä¢ Desvio padr√£o: {best_scores.std():.4f}\")\n",
    "    print(f\"  ‚Ä¢ Melhoria m√©dia: {(best_scores.mean() - avg_convergence[('avg_f1_score', 'mean')].iloc[0]):.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado de converg√™ncia encontrado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avalia√ß√£o Final do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar avalia√ß√£o final com valida√ß√£o cruzada\n",
    "print(\"üîç Iniciando avalia√ß√£o final do melhor modelo...\")\n",
    "print(\"üìä Ser√° executada valida√ß√£o cruzada estratificada com 5 folds.\")\n",
    "\n",
    "final_results = evaluate_final_model.evaluate_best_model()\n",
    "\n",
    "print(\"\\n‚úÖ Avalia√ß√£o final conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados detalhados\n",
    "cv_metrics = final_results['cv_metrics']\n",
    "global_metrics = final_results['global_metrics']\n",
    "\n",
    "print(\"üéØ RESULTADOS FINAIS DA VALIDA√á√ÉO CRUZADA:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"F1-Score:  {cv_metrics['f1_mean']:.4f} ¬± {cv_metrics['f1_std']:.4f}\")\n",
    "print(f\"Accuracy:  {cv_metrics['accuracy_mean']:.4f} ¬± {cv_metrics['accuracy_std']:.4f}\")\n",
    "print(f\"AUC-ROC:   {cv_metrics['auc_mean']:.4f} ¬± {cv_metrics['auc_std']:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüéØ M√âTRICAS GLOBAIS:\")\n",
    "print(f\"F1-Score:  {global_metrics['f1_score']:.4f}\")\n",
    "print(f\"Accuracy:  {global_metrics['accuracy']:.4f}\")\n",
    "print(f\"AUC-ROC:   {global_metrics['auc']:.4f}\")\n",
    "\n",
    "# Matriz de confus√£o\n",
    "cm = global_metrics['confusion_matrix']\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nüî¢ MATRIZ DE CONFUS√ÉO:\")\n",
    "print(f\"Verdadeiros Negativos: {tn}\")\n",
    "print(f\"Falsos Positivos: {fp}\")\n",
    "print(f\"Falsos Negativos: {fn}\")\n",
    "print(f\"Verdadeiros Positivos: {tp}\")\n",
    "\n",
    "# M√©tricas adicionais\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print(f\"\\nüìà M√âTRICAS DETALHADAS:\")\n",
    "print(f\"Precis√£o: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Especificidade: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exporta√ß√£o e Relat√≥rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar todos os resultados\n",
    "print(\"üíæ Exportando resultados...\")\n",
    "\n",
    "# Exportar dados do PSO para CSV\n",
    "database_utils.export_results_to_csv()\n",
    "\n",
    "# Validar integridade do banco\n",
    "validation = database_utils.validate_database()\n",
    "print(f\"\\n‚úÖ Valida√ß√£o do banco de dados:\")\n",
    "print(f\"  ‚Ä¢ Tabelas encontradas: {validation['tables_found']}\")\n",
    "print(f\"  ‚Ä¢ Registros pso_resultados: {validation['pso_resultados_count']:,}\")\n",
    "print(f\"  ‚Ä¢ Registros pso_execucao: {validation['pso_execucao_count']}\")\n",
    "print(f\"  ‚Ä¢ Experimentos √∫nicos: {validation['unique_experiments']}\")\n",
    "print(f\"  ‚Ä¢ Experimentos esperados: {validation['expected_experiments']}\")\n",
    "\n",
    "# Listar arquivos gerados\n",
    "import os\n",
    "files_generated = []\n",
    "for file in os.listdir('.'):\n",
    "    if file.endswith(('.csv', '.txt', '.png', '.db')):\n",
    "        files_generated.append(file)\n",
    "\n",
    "print(f\"\\nüìÅ Arquivos gerados:\")\n",
    "for file in sorted(files_generated):\n",
    "    size = os.path.getsize(file) / 1024  # KB\n",
    "    print(f\"  ‚Ä¢ {file} ({size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final do projeto\n",
    "print(\"üéâ PROJETO CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Informa√ß√µes do dataset\n",
    "print(f\"üìä Dataset: {len(df)} amostras, {len(df.columns)-1} features\")\n",
    "print(f\"üéØ Problema: Classifica√ß√£o bin√°ria de Parkinson\")\n",
    "\n",
    "# Configura√ß√£o PSO\n",
    "print(f\"\\n‚öôÔ∏è Configura√ß√£o PSO:\")\n",
    "print(f\"  ‚Ä¢ {config.PSO_CONFIG['experimentos']} experimentos independentes\")\n",
    "print(f\"  ‚Ä¢ {config.PSO_CONFIG['n_particles']} part√≠culas por experimento\")\n",
    "print(f\"  ‚Ä¢ {config.PSO_CONFIG['iters']} itera√ß√µes por experimento\")\n",
    "print(f\"  ‚Ä¢ {config.PSO_CONFIG['experimentos'] * config.PSO_CONFIG['n_particles'] * config.PSO_CONFIG['iters']:,} avalia√ß√µes totais\")\n",
    "\n",
    "# Melhor resultado\n",
    "if 'final_results' in locals():\n",
    "    cv_metrics = final_results['cv_metrics']\n",
    "    print(f\"\\nüèÜ Melhor Resultado (Valida√ß√£o Cruzada):\")\n",
    "    print(f\"  ‚Ä¢ F1-Score: {cv_metrics['f1_mean']:.4f} ¬± {cv_metrics['f1_std']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Accuracy: {cv_metrics['accuracy_mean']:.4f} ¬± {cv_metrics['accuracy_std']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ AUC-ROC: {cv_metrics['auc_mean']:.4f} ¬± {cv_metrics['auc_std']:.4f}\")\n",
    "\n",
    "# Arquitetura do melhor modelo\n",
    "if 'best_particle' in locals() and best_particle:\n",
    "    best_params = model_utils.decode_particle_position(best_particle['position'])\n",
    "    print(f\"\\nüèóÔ∏è Melhor Arquitetura:\")\n",
    "    print(f\"  ‚Ä¢ Camadas: {best_params['n_layers']}\")\n",
    "    print(f\"  ‚Ä¢ Neur√¥nios: {best_params['neurons'][:best_params['n_layers']]}\")\n",
    "    print(f\"  ‚Ä¢ Learning Rate: {best_params['learning_rate']:.6f}\")\n",
    "\n",
    "# Arquivos gerados\n",
    "print(f\"\\nüìÅ Arquivos principais gerados:\")\n",
    "print(f\"  ‚Ä¢ pso_parkinson.db - Banco SQLite com todos os resultados\")\n",
    "print(f\"  ‚Ä¢ pso_resultados.csv - Dados detalhados das part√≠culas\")\n",
    "print(f\"  ‚Ä¢ pso_execucao.csv - Resumo dos experimentos\")\n",
    "print(f\"  ‚Ä¢ relatorio_avaliacao_final.txt - Relat√≥rio completo\")\n",
    "print(f\"  ‚Ä¢ matriz_confusao.png - Visualiza√ß√£o da matriz de confus√£o\")\n",
    "\n",
    "print(\"\\n‚úÖ Sistema PSO implementado e testado com sucesso!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
