#--------------IMPORTACOES E CONFIGURACAO INICIAL-------------------
# Importa√ß√µes principais
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
import warnings

# Configurar warnings
warnings.filterwarnings('ignore')

# Configurar matplotlib
plt.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12, 8)

# Importar m√≥dulos do projeto
import config
import data_utils
import model_utils
import database_utils
import pso_optimizer
import evaluate_final_model

print("‚úÖ Importa√ß√µes realizadas com sucesso!")
print(f"üìä Configura√ß√£o PSO: {config.PSO_CONFIG['n_particles']} part√≠culas, {config.PSO_CONFIG['iters']} itera√ß√µes, {config.PSO_CONFIG['experimentos']} experimentos")


#--------------EXPLORACAO DOS DADOS-------------------
# Carregar e explorar dados
print("üìä Carregando dataset de Parkinson...")
df = data_utils.load_parkinson_data()

# Validar dados
data_utils.validate_data(df)

# Informa√ß√µes do dataset
info = data_utils.get_data_info(df)
print(f"\nüìà Informa√ß√µes do Dataset:")
print(f"  ‚Ä¢ Amostras: {info['n_samples']}")
print(f"  ‚Ä¢ Features: {info['n_features']}")
print(f"  ‚Ä¢ Distribui√ß√£o de classes: {info['target_distribution']}")
print(f"  ‚Ä¢ Valores ausentes: {info['missing_values']}")

# Mostrar primeiras linhas
#display(df.head())


# Visualizar distribui√ß√£o das classes
#plt.figure(figsize=(10, 6))

# Gr√°fico de barras
#plt.subplot(1, 2, 1)
class_counts = df['status'].value_counts()
#plt.bar(['Saud√°vel (0)', 'Parkinson (1)'], class_counts.values, color=['lightblue', 'lightcoral'])
#plt.title('Distribui√ß√£o das Classes')
#plt.ylabel('N√∫mero de Amostras')

# Gr√°fico de pizza
#plt.subplot(1, 2, 2)
#plt.pie(class_counts.values, labels=['Saud√°vel', 'Parkinson'], autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])
#plt.title('Propor√ß√£o das Classes')

#plt.tight_layout()
#plt.show()

print(f"Dataset balanceado: {'Sim' if abs(class_counts[0] - class_counts[1]) / len(df) < 0.1 else 'N√£o'}")


#--------------PREPARACAO DOS DADOS-------------------
# Preparar dados para valida√ß√£o cruzada
print("üîÑ Preparando dados para valida√ß√£o cruzada...")
X_data, y_data, scaler = data_utils.prepare_data_for_cv(df)

print(f"‚úÖ Dados preparados:")
print(f"  ‚Ä¢ Shape X: {X_data.shape}")
print(f"  ‚Ä¢ Shape y: {y_data.shape}")
print(f"  ‚Ä¢ Tipo de normaliza√ß√£o: MinMaxScaler")
print(f"  ‚Ä¢ Range dos dados: [{X_data.min():.3f}, {X_data.max():.3f}]")


#--------------TESTE RAPIDO DA REDE NEURAL-------------------
# Testar cria√ß√£o e treino de uma rede neural simples
print("üß™ Testando cria√ß√£o e treino da rede neural...")

# Par√¢metros de teste
test_params = {
    'n_layers': 2,
    'neurons': [64, 32],
    'learning_rate': 0.001
}

# Dividir dados para teste
from sklearn.model_selection import train_test_split
X_train_test, X_val_test, y_train_test, y_val_test = train_test_split(
    X_data, y_data, test_size=0.2, random_state=42, stratify=y_data
)

# Criar e treinar modelo
test_model = model_utils.create_neural_network(X_data.shape[1], test_params)
print(f"‚úÖ Modelo criado com arquitetura: {test_params['neurons']}")

# Treinar por algumas √©pocas
history = model_utils.train_neural_network(
    test_model, X_train_test, y_train_test, 
    X_val_test, y_val_test, epochs=10, verbose=1
)

# Avaliar modelo
metrics = model_utils.evaluate_model(test_model, X_val_test, y_val_test)
print(f"\nüìä M√©tricas do teste:")
print(f"  ‚Ä¢ F1-Score: {metrics['f1_score']:.4f}")
print(f"  ‚Ä¢ Accuracy: {metrics['accuracy']:.4f}")
print(f"  ‚Ä¢ AUC: {metrics['auc']:.4f}")

# Limpar mem√≥ria
del test_model
import tensorflow as tf
tf.keras.backend.clear_session()

print("‚úÖ Teste da rede neural conclu√≠do com sucesso!")

#--------------EXECUCAO OTIMIZACAO PSO-------------------
# Verificar configura√ß√µes antes de executar
print("‚öôÔ∏è Configura√ß√µes atuais do PSO:")
print(f"  ‚Ä¢ Experimentos: {config.PSO_CONFIG['experimentos']}")
print(f"  ‚Ä¢ Part√≠culas por experimento: {config.PSO_CONFIG['n_particles']}")
print(f"  ‚Ä¢ Itera√ß√µes por experimento: {config.PSO_CONFIG['iters']}")
print(f"  ‚Ä¢ Total de treinamentos: {config.PSO_CONFIG['experimentos'] * config.PSO_CONFIG['n_particles'] * config.PSO_CONFIG['iters']:,}")

# Estimar tempo
estimated_time_hours = (config.PSO_CONFIG['experimentos'] * config.PSO_CONFIG['n_particles'] * config.PSO_CONFIG['iters'] * 2) / 3600
print(f"  ‚Ä¢ Tempo estimado: ~{estimated_time_hours:.1f} horas")

print("\nüí° Para teste r√°pido, edite config.py e reduza os valores.")

# Executar otimiza√ß√£o PSO
print("üöÄ Iniciando otimiza√ß√£o PSO...")
print("üìä Progresso ser√° mostrado com barras de progresso interativas.")
print("üíæ Todos os dados ser√£o salvos automaticamente no banco SQLite.")

# Executar otimiza√ß√£o
pso_results = pso_optimizer.run_pso_optimization()

print("\nüéâ Otimiza√ß√£o PSO conclu√≠da com sucesso!")
print(f"üèÜ Melhor F1-Score encontrado: {pso_results['best_experiment']['best_f1_score']:.4f}")

#--------------ANALISE RSULTADOS PSO-------------------
# Obter estat√≠sticas dos experimentos
stats = database_utils.get_experiment_statistics()

print("üìä Estat√≠sticas dos Experimentos PSO:")
print(f"  ‚Ä¢ Total de experimentos: {int(stats.get('total_experiments', 0))}")
print(f"  ‚Ä¢ Total de part√≠culas avaliadas: {int(stats.get('total_particles', 0)):,}")
print(f"  ‚Ä¢ F1-Score m√©dio: {stats.get('avg_f1_score', 0):.4f}")
print(f"  ‚Ä¢ Melhor F1-Score: {stats.get('best_f1_score', 0):.4f}")
print(f"  ‚Ä¢ Pior F1-Score: {stats.get('worst_f1_score', 0):.4f}")
print(f"  ‚Ä¢ Desvio padr√£o F1: {stats.get('std_f1_score', 0):.4f}")
print(f"  ‚Ä¢ Tempo m√©dio por experimento: {stats.get('avg_total_time', 0):.1f}s")
print(f"  ‚Ä¢ Uso m√©dio de CPU: {stats.get('avg_cpu_usage', 0):.1f}%")
print(f"  ‚Ä¢ Uso m√°ximo de mem√≥ria: {stats.get('avg_max_memory', 0):.1f} MB")